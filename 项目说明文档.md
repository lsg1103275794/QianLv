# 千虑 (QianLv) - 智能文本分析与研报生成系统

## 项目概述

千虑 (QianLv) 是一个基于大语言模型(LLM)的智能文本分析与研报生成系统。该系统集成了文本分析、风格迁移、多维度文学分析、智能研报生成等多项功能，支持多种AI服务提供商，为用户提供强大的文本处理和分析能力。

**核心特性：**
- 🔍 多维度文本分析（情感分析、关键词提取、可读性分析等）
- 📝 文学创作多维分析（基于专业模板的深度分析）
- 🎨 文本风格迁移与转换
- 📊 智能数据研报生成（基于热点话题或用户定义主题）
- 🌐 多AI服务商支持（Ollama、Deepseek、Google Gemini等14+提供商）
- 💬 交互式聊天测试界面
- 🗄️ 结果数据库管理与导出

**技术栈：**
- 后端：Python 3.12 + FastAPI + SQLAlchemy + Uvicorn
- 前端：Vue 3 + Element Plus + ECharts + Vue Router
- AI集成：多种LLM服务商API + Ollama本地部署
- 数据处理：Pandas、NLTK、Jieba、Sentence-Transformers

---

## 目录

- [项目概述](#项目概述)
- [项目结构](#项目结构)
- [核心功能](#核心功能)
- [技术架构](#技术架构)
- [安装部署](#安装部署)
- [配置说明](#配置说明)
- [使用指南](#使用指南)
- [API文档](#api文档)
- [开发规范](#开发规范)

---

## 项目结构

### 完整目录树

```
千虑 (QianLv)/
├── backend_main.py              # 后端主入口文件
├── main.py                      # 简化启动入口（包装backend_main.py）
├── requirements.txt             # Python依赖清单
├── .env                         # 环境变量配置（API密钥等敏感信息）
├── .gitignore                   # Git忽略文件配置
├── 后端.bat                     # Windows快速启动脚本
│
├── frontend/                    # 前端项目目录
│   ├── package.json             # 前端依赖配置
│   ├── vue.config.js            # Vue CLI配置
│   ├── babel.config.js          # Babel编译配置
│   ├── .eslintrc.js             # ESLint代码规范配置
│   ├── public/                  # 静态资源目录
│   │   └── index.html           # HTML模板
│   ├── dist/                    # 构建输出目录（生产环境）
│   └── src/                     # 前端源代码
│       ├── App.vue              # 根组件
│       ├── main.js              # 前端入口文件
│       ├── router/              # 路由配置
│       │   └── index.js         # 路由定义
│       ├── views/               # 页面视图
│       │   ├── DataTerminal.vue           # 数据终端（结果管理）
│       │   ├── ModelTestView.vue          # 模型测试（聊天界面）
│       │   └── ReportGeneratorView.vue    # 研报生成器
│       ├── components/          # 可复用组件
│       │   ├── analysis/        # 分析相关组件
│       │   │   ├── TextAnalysis.vue       # 文本分析主界面
│       │   │   ├── WritingStyleAnalysis.vue # 写作风格分析
│       │   │   ├── AnalysisResults.vue    # 分析结果展示
│       │   │   ├── SentimentChart.vue     # 情感分析图表
│       │   │   ├── KeywordExtractionChart.vue # 关键词提取图表
│       │   │   ├── ReadabilityChart.vue   # 可读性分析图表
│       │   │   └── ...（其他分析组件）
│       │   ├── api/             # API配置相关组件
│       │   │   ├── ApiManager.vue         # API管理器主界面
│       │   │   ├── ApiProviderCard.vue    # 服务商卡片
│       │   │   ├── ApiConfigDrawer.vue    # 配置抽屉
│       │   │   ├── ApiStatusCheck.vue     # 状态检查
│       │   │   └── ...
│       │   ├── chat/            # 聊天界面组件
│       │   │   ├── ChatTest.vue           # 聊天测试主组件
│       │   │   ├── components/            # 聊天子组件
│       │   │   │   ├── ChatHeader.vue     # 聊天头部
│       │   │   │   ├── ChatMessages.vue   # 消息列表
│       │   │   │   ├── ChatInput.vue      # 输入框
│       │   │   │   └── MessageItem.vue    # 消息项
│       │   │   ├── composables/           # 可组合函数
│       │   │   ├── styles/                # 样式文件
│       │   │   └── utils/                 # 工具函数
│       │   ├── common/          # 通用组件
│       │   │   ├── ConfigForm.vue         # 配置表单
│       │   │   ├── LanguageSwitcher.vue   # 语言切换器
│       │   │   ├── ModelParamsEditor.vue  # 模型参数编辑器
│       │   │   └── ...
│       │   ├── diagnostics/     # 诊断工具组件
│       │   ├── report-generator/ # 研报生成组件
│       │   │   ├── ReportForm.vue         # 研报表单
│       │   │   ├── ReportDisplay.vue      # 研报显示
│       │   │   ├── ReportLoading.vue      # 加载状态
│       │   │   └── ReportError.vue        # 错误显示
│       │   ├── style/           # 风格迁移组件
│       │   │   └── StyleTransfer.vue      # 风格转换主界面
│       │   └── charts/          # 图表组件
│       ├── services/            # API服务层
│       │   ├── api.js           # 基础API配置
│       │   ├── apiClient.js     # API客户端
│       │   ├── analysisService.js      # 分析服务
│       │   ├── chatService.js          # 聊天服务
│       │   ├── reportService.js        # 研报服务
│       │   ├── providerService.js      # 服务商管理
│       │   ├── fileService.js          # 文件服务
│       │   ├── resultsService.js       # 结果管理服务
│       │   └── ...
│       ├── i18n/                # 国际化配置
│       │   ├── index.js         # i18n配置入口
│       │   └── locales/         # 语言文件
│       │       ├── zh-CN.js     # 简体中文
│       │       └── en-US.js     # 英文
│       ├── utils/               # 工具函数
│       └── assets/              # 静态资源
│           ├── main.css         # 主样式文件
│           ├── emojiMap.js      # Emoji映射
│           └── styles/          # 样式文件
│
├── src/                         # 后端源代码
│   ├── api/                     # API路由和模型
│   │   ├── routes/              # API路由定义
│   │   │   ├── analysis.py              # 文本分析路由
│   │   │   ├── literature_analysis.py   # 文学分析路由
│   │   │   ├── chat.py                  # 聊天路由
│   │   │   ├── chat_history.py          # 聊天历史路由
│   │   │   ├── providers.py             # 服务商管理路由
│   │   │   ├── files.py                 # 文件上传路由
│   │   │   ├── transfer.py              # 风格迁移路由
│   │   │   ├── report_generator_api.py  # 研报生成路由
│   │   │   ├── hot_topics_routes.py     # 热点话题路由
│   │   │   ├── results.py               # 结果管理路由
│   │   │   ├── tasks.py                 # 任务管理路由
│   │   │   ├── templates.py             # 模板管理路由
│   │   │   ├── settings.py              # 设置路由
│   │   │   ├── data_terminal.py         # 数据终端路由
│   │   │   ├── ui_state.py              # UI状态路由
│   │   │   └── async_tasks.py           # 异步任务路由
│   │   ├── models/              # 数据模型
│   │   │   ├── analysis.py              # 分析模型
│   │   │   ├── report_models.py         # 研报模型
│   │   │   └── hot_topic_models.py      # 热点话题模型
│   │   └── auth.py              # 认证逻辑
│   │
│   ├── core/                    # 核心业务逻辑
│   │   ├── literature_analyzer.py    # 文学分析器
│   │   ├── analyzers/           # 分析器模块
│   │   │   └── basic_analyzer.py     # 基础分析器
│   │   ├── processing/          # 文本处理模块
│   │   │   ├── chunk_splitter.py     # 文本分块
│   │   │   ├── format_enforcer.py    # 格式强制器
│   │   │   ├── post_processor.py     # 后处理器
│   │   │   ├── style_transfer.py     # 风格迁移
│   │   │   └── style_validator.py    # 风格验证
│   │   └── tasks/               # 任务管理
│   │       ├── manager.py            # 任务管理器
│   │       ├── models.py             # 任务模型
│   │       └── worker.py             # 任务执行器
│   │
│   ├── providers/               # AI服务提供商
│   │   ├── base.py              # 基础处理器类
│   │   ├── factory.py           # 处理器工厂
│   │   └── handlers/            # 各服务商处理器
│   │       ├── ollama_local.py           # Ollama本地服务
│   │       ├── ollama_report_handler.py  # Ollama研报处理器
│   │       ├── deepseek_ai.py            # Deepseek AI
│   │       ├── silicon_flow.py           # 硅基流动
│   │       ├── volc_engine.py            # 火山引擎
│   │       ├── google_gemini.py          # Google Gemini
│   │       ├── zhipu_ai.py               # 智谱AI
│   │       ├── groq_api.py               # Groq API
│   │       ├── together_ai.py            # Together AI
│   │       ├── mistral_ai.py             # Mistral AI
│   │       ├── perplexity_ai.py          # Perplexity AI
│   │       ├── open_router.py            # OpenRouter
│   │       ├── Free_Qwen3.py             # 免费Qwen3
│   │       └── ...（其他处理器）
│   │
│   ├── services/                # 业务服务层
│   │   ├── hot_topics/          # 热点话题服务
│   │   │   ├── service.py            # 服务逻辑
│   │   │   └── handler.py            # 处理器
│   │   └── report_generator/    # 研报生成服务
│   │       └── service.py            # 服务逻辑
│   │
│   ├── database/                # 数据库管理
│   │   └── manager.py           # 数据库管理器
│   │
│   ├── config/                  # 配置管理
│   │   ├── api_manager.py       # API管理器
│   │   ├── app_config.py        # 应用配置
│   │   └── analyzer_config.json # 分析器配置
│   │
│   ├── utils/                   # 工具函数
│   │   ├── logging.py           # 日志工具
│   │   ├── config.py            # 配置工具
│   │   ├── cache.py             # 缓存工具
│   │   ├── error_handler.py     # 错误处理
│   │   ├── file_utils.py        # 文件工具
│   │   ├── helpers.py           # 辅助函数
│   │   ├── retry.py             # 重试机制
│   │   ├── startup.py           # 启动处理
│   │   ├── ui_state.py          # UI状态管理
│   │   ├── config_validator.py  # 配置验证
│   │   └── provider_config_loader.py # 服务商配置加载器
│   │
│   └── validation/              # 数据验证
│       ├── schema_checker.py    # 模式检查器
│       ├── style_detector.py    # 风格检测器
│       └── error_handler.py     # 错误处理器
│
├── config/                      # 配置文件目录
│   ├── app_config.yaml          # 应用配置
│   ├── api_configs.json         # API配置
│   ├── configs.json             # 通用配置
│   ├── providers_meta.json      # 服务商元数据（14+提供商）
│   ├── provider_config_template.json # 服务商配置模板
│   ├── providers/               # 各服务商配置文件
│   │   ├── ollama_local.json    # Ollama配置
│   │   ├── open_router.json     # OpenRouter配置
│   │   └── Free_Qwen3.json      # Qwen3配置
│   ├── prompt_templates/        # 提示词模板
│   │   ├── literary_analysis.yaml            # 文学分析
│   │   ├── character_plot_analysis.yaml      # 角色情节分析
│   │   ├── theme_symbolism_analysis.yaml     # 主题象征分析
│   │   └── comprehensive_literary_review.yaml # 综合文学评论
│   ├── promptPRO/               # 专业提示词模板
│   │   └── 文学创作多维分析模板 v2.yaml    # V2多维度文学分析
│   └── validation_rules/        # 验证规则
│       ├── alpaca_schema.json   # Alpaca格式规范
│       └── style_rules.yaml     # 风格规则
│
├── data/                        # 数据目录
│   ├── QianLv_data.db        # SQLite数据库
│   ├── sensitive_words.txt      # 敏感词库
│   ├── ui_state.json            # UI状态存储
│   ├── uploads/                 # 上传文件存储
│   │   └── temp/                # 临时文件
│   └── output/                  # 输出数据
│       └── datasets/            # 数据集
│
├── .cache/                      # 缓存目录
│   ├── index/                   # 索引缓存
│   ├── style_transfer/          # 风格迁移缓存
│   ├── text_analysis/           # 文本分析缓存
│   └── text_processing/         # 文本处理缓存
│
├── conda_env/                   # Conda环境（Python 3.12）
│   ├── python.exe               # Python解释器
│   ├── Scripts/                 # 脚本工具
│   ├── Lib/                     # Python库
│   └── ...
│
├── doc/                         # 文档目录
│   ├── PROJECT_STRUCTURE.md     # 项目结构说明
│   ├── README_API_IMPROVEMENTS.md # API改进说明
│   ├── INTELLIGENT_REPORT_SYSTEM.md # 智能研报系统设计
│   ├── 数据研报功能的实现.md    # 数据研报功能实现文档
│   ├── development_log.md       # 开发日志
│   ├── api_streaming_guide.md   # API流式传输指南
│   └── MCP.md                   # MCP相关文档
│
├── Future/                      # 未来功能规划
│   └── feature_suggestions.md   # 功能建议
│
└── .cursor/                     # Cursor IDE配置
    ├── mcp.json                 # MCP配置
    └── rules/                   # 开发规则
        ├── apiseting.mdc        # API设置规则
        ├── readme.mdc           # README规则
        └── vueseting.mdc        # Vue设置规则
```

---

## 核心功能

### 1. 文本分析模块 📊
**路径：** `/text-analysis`  
**核心文件：** `frontend/src/components/analysis/TextAnalysis.vue` | `src/api/routes/analysis.py`

**功能特性：**
- **情感分析**：识别文本情感倾向（正面、负面、中性），支持情感强度评分
- **关键词提取**：自动提取文本核心关键词，支持TF-IDF、TextRank等算法
- **可读性分析**：计算Flesch可读性指数、平均句长、词汇多样性等指标
- **文本统计**：字数统计、句子数、段落数、平均词长等基础统计
- **词频分析**：生成词云图、词频分布图表
- **语言特征分析**：语法结构、修辞手法、语言风格识别
- **句式模式分析**：识别文本中的句式结构和表达模式

**支持文件格式：** TXT, PDF, DOCX, EPUB, MD

### 2. 文学创作多维分析 📚
**路径：** `/writing-style-analysis`  
**核心文件：** `src/core/literature_analyzer.py` | `src/api/routes/literature_analysis.py`

**功能特性：**
- **基于V2多维度模板**：使用专业的文学分析模板（`config/promptPRO/文学创作多维分析模板 v2.yaml`）
- **可选维度分析**：用户可选择多个分析维度进行深度分析
  - 人物塑造（性格特点、发展弧线、关系网络）
  - 情节构建（叙事结构、冲突设置、节奏控制）
  - 主题探讨（核心思想、象征意义、社会意义）
  - 语言风格（修辞手法、词汇选择、句式特点）
  - 写作技巧（叙事视角、时空处理、描写手法）
- **风格迁移深度集成**：**文学创作分析为风格迁移模块提供核心服务**。
  - **基于分析样本的改写**：系统可以提取文学分析后的文本风格样本，直接服务于风格迁移模块。
  - **应用场景**：可用于文案改写、洗稿、文章润色等，基于分析出的风格特征进行精准的文章改写。
- **专业分析报告**：生成结构化的文学分析报告
- **模板可扩展**：支持自定义分析模板和维度

### 3. 风格迁移模块 🎨
**路径：** `/style-transfer`  
**核心文件：** `frontend/src/components/style/StyleTransfer.vue` | `src/core/processing/style_transfer.py`

**功能特性：**
- **风格转换**：将文本从一种风格转换为另一种风格
- **文学分析联动**：支持导入「文学创作分析」模块生成的风格样本，实现更高质量的改写。
- **预设风格库**：提供多种预设风格（正式/非正式、学术/通俗、文言/白话等）
- **自定义风格**：支持用户定义目标风格特征
- **风格验证**：验证转换后的文本是否符合目标风格
- **风格分析缓存**：缓存风格分析结果以提高效率
- **文案/洗稿支持**：专门优化了针对洗稿和文案重构的流程，基于深度风格特征进行改写。

### 4. 智能研报生成系统 📈
**路径：** `/report-generator`  
**核心文件：** `src/services/report_generator/service.py` | `src/api/routes/report_generator_api.py`

**功能特性：**
- **LLM驱动的研报生成**：
  - 用户输入主题，LLM自动规划搜索策略
  - 调用Web搜索工具获取实时信息
  - LLM分析整合搜索结果，生成结构化研报
- **多种生成方式**：
  - **Ollama本地生成**：使用本地Ollama服务生成研报
  - **云端API生成**：使用云端AI服务（支持14+提供商）
  - **基于热点话题生成**：从热点话题中筛选相关内容生成研报
- **研报结构**：
  - 执行摘要
  - 背景介绍
  - 详细分析（按维度展开）
  - 关键数据点
  - 趋势预测
  - 结论与建议
- **Markdown格式输出**：支持富文本格式，可直接导出

### 5. 热点话题追踪 🔥
**路径：** `/api/v1/hot-topics`  
**核心文件：** `src/services/hot_topics/service.py` | `src/services/hot_topics/handler.py`

**功能特性：**
- **实时热点获取**：通过Serper API或模拟搜索获取热点信息
- **热点分类**：自动分类热点话题（科技、财经、社会等）
- **热度评分**：计算话题的相关性和热度评分
- **来源追踪**：记录热点信息的来源媒体和URL
- **智能摘要**：对热点内容进行自动摘要
- **关键词提取**：提取热点话题的核心关键词

### 6. 多AI服务商管理 🤖
**路径：** `/settings-manager`  
**核心文件：** `frontend/src/components/api/ApiManager.vue` | `src/providers/factory.py`

**支持的AI服务商（14+）：**
1. **Ollama Local** - 本地部署的开源模型
2. **Deepseek AI** - 深度求索
3. **Silicon Flow** - 硅基流动
4. **Volc Engine** - 火山引擎
5. **Google Gemini** - Google AI
6. **Zhipu AI** - 智谱AI
7. **Groq API** - Groq加速推理
8. **Together AI** - Together平台
9. **Mistral AI** - Mistral模型
10. **Perplexity AI** - Perplexity搜索增强
11. **OpenRouter** - 多模型路由
12. **Free Qwen3** - 免费Qwen3服务
13. **Anyscale Endpoints** - Anyscale平台
14. **Cohere Compatible** - Cohere兼容接口

**管理功能：**
- **统一配置界面**：可视化配置所有AI服务商
- **实时参数更新**：修改配置后无需重启服务即可生效
- **连接状态检测**：测试API连接和模型可用性
- **参数可视化编辑**：温度、最大token数、Top-P等参数
- **API密钥管理**：安全管理各服务商的API密钥

### 7. 交互式聊天测试 💬
**路径：** `/model-test`  
**核心文件：** `frontend/src/views/ModelTestView.vue` | `src/api/routes/chat.py`

**功能特性：**
- **多模型对话测试**：支持切换不同AI模型进行对话
- **流式输出**：实时显示AI生成的回复（支持SSE）
- **对话历史管理**：保存和加载历史对话记录
- **上下文维护**：保持多轮对话的上下文连贯性
- **Markdown渲染**：支持富文本消息展示
- **代码高亮**：自动识别和高亮代码块
- **思考过程展示**：显示AI的思考过程（如果模型支持）

### 8. 数据终端（结果管理）🗄️
**路径：** `/data-terminal`  
**核心文件：** `frontend/src/views/DataTerminal.vue` | `src/api/routes/results.py`

**功能特性：**
- **结果列表管理**：查看所有分析和生成的结果
- **结果分类**：按类型分类（文本分析、风格迁移、研报等）
- **元数据展示**：显示生成时间、使用模型、来源信息
- **结果重命名**：自定义结果名称
- **多格式导出**：
  - Markdown (.md)
  - Word文档 (.docx)
  - 纯文本 (.txt)
- **结果删除**：清理不需要的结果
- **结果查看**：快速预览结果内容

---
## 安装部署

### 环境要求

**后端环境：**
- Python 3.12+
- Conda（推荐）或虚拟环境
- 至少4GB可用内存
- 磁盘空间：至少10GB（包含模型缓存）

**前端环境：**
- Node.js 16+ 
- npm 8+ 或 yarn

**可选（本地模型）：**
- Ollama（用于本地模型部署）
- CUDA支持的GPU（加速推理，可选）

### 安装步骤

#### 1. 克隆项目
```bash
git clone <repository-url>
cd QianLv
```

#### 2. 后端安装

**方法一：使用项目自带的Conda环境（推荐）**
```bash
# 项目已包含conda_env目录，直接使用
# Windows:
.\conda_env\python.exe -m pip install -r requirements.txt

# Linux/Mac:
./conda_env/bin/python -m pip install -r requirements.txt
```

**方法二：创建新的Conda环境**
```bash
# 创建Python 3.12环境
conda create -n QianLv python=3.12
conda activate QianLv

# 安装依赖
pip install -r requirements.txt
```

**方法三：使用虚拟环境**
```bash
# 创建虚拟环境
python -m venv venv

# 激活虚拟环境
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# 安装依赖
pip install -r requirements.txt
```

#### 3. 前端安装

```bash
cd frontend
npm install
# 或使用 yarn
yarn install
```

#### 4. 配置环境变量

复制并编辑`.env`文件，配置API密钥和服务端点：

```bash
# 编辑 .env 文件
# 至少配置一个AI服务商的API密钥

# 示例：配置Ollama本地服务
OLLAMA_ENDPOINT=http://localhost:11434
OLLAMA_DEFAULT_MODEL=gemma3:12b

# 或配置云端服务
DEEPSEEK_API_KEY=your_api_key_here
DEEPSEEK_DEFAULT_MODEL=deepseek-chat

# 配置搜索API（用于研报生成）
SERPER_API_KEY=your_serper_api_key
```

#### 5. 初始化数据库

```bash
# 数据库会在首次启动时自动创建
# 位置：data/QianLv_data.db
```

### 启动应用

#### 开发模式

**启动后端：**
```bash
# 方法一：使用Python直接运行
python backend_main.py

# 方法二：使用uvicorn
uvicorn backend_main:app --reload --host 0.0.0.0 --port 8000

# 方法三：Windows快捷启动
.\后端.bat
```

**启动前端：**
```bash
cd frontend
npm run serve
# 或
yarn serve
```

前端默认访问地址：`http://localhost:8080`  
后端API地址：`http://localhost:8000`  
API文档地址：`http://localhost:8000/docs`

#### 生产模式

**1. 构建前端：**
```bash
cd frontend
npm run build
# 构建产物在 frontend/dist/
```

**2. 启动后端（会自动服务前端静态文件）：**
```bash
# 使用生产配置
python backend_main.py

# 或使用gunicorn（Linux/Mac）
gunicorn -w 4 -k uvicorn.workers.UvicornWorker backend_main:app --bind 0.0.0.0:8000
```

访问地址：`http://localhost:8000`

### Docker部署（可选）

**创建Dockerfile：**
```dockerfile
FROM python:3.12-slim

WORKDIR /app

# 安装系统依赖
RUN apt-get update && apt-get install -y \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# 复制依赖文件
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# 复制项目文件
COPY . .

# 构建前端
WORKDIR /app/frontend
RUN npm install && npm run build

# 返回项目根目录
WORKDIR /app

# 暴露端口
EXPOSE 8000

# 启动命令
CMD ["python", "backend_main.py"]
```

**构建和运行：**
```bash
docker build -t QianLv .
docker run -p 8000:8000 -v G:\work\QianLv/.env:/app/.env QianLv
```

---

## 配置说明

### 1. 环境变量配置（.env）

`.env`文件是配置的核心，包含所有API密钥和服务配置：

```bash
# === 默认服务商 ===
DEFAULT_PROVIDER='ollama_local'

# === Ollama本地服务 ===
OLLAMA_ENDPOINT='http://localhost:11434'
OLLAMA_DEFAULT_MODEL='gemma3:12b'
OLLAMA_TEMPERATURE='0.85'
OLLAMA_MAX_TOKENS='100000'

# === Deepseek AI ===
DEEPSEEK_API_KEY='your_api_key'
DEEPSEEK_ENDPOINT='https://api.deepseek.com'
DEEPSEEK_DEFAULT_MODEL='deepseek-chat'
DEEPSEEK_TEMPERATURE='0.95'
DEEPSEEK_MAX_TOKENS='8096'

# === Google Gemini ===
GOOGLE_API_KEY='your_google_api_key'
GOOGLE_DEFAULT_MODEL='gemini-1.5-flash-latest'

# === 搜索服务（研报生成） ===
SERPER_API_KEY='your_serper_api_key'

# === 系统配置 ===
LOG_LEVEL='DEBUG'
CACHE_SIZE='512'
```

### 2. 服务商元数据（config/providers_meta.json）

定义所有支持的AI服务商及其配置映射关系：

```json
[
  {
    "standard_name": "ollama_local",
    "display_name": "Ollama Local",
    "handler_module_path": "src.providers.handlers.ollama_local",
    "handler_class_name": "OllamaLocalHandler",
    "aliases": ["ollama", "ollamalocal"],
    "env_prefix": "OLLAMA_",
    "config_path": "config/providers/ollama_local.json"
  }
]
```

### 3. 提示词模板配置

**文学分析模板（config/promptPRO/文学创作多维分析模板 v2.yaml）：**

```yaml
metadata:
  name: "文学创作多维分析模板 v2"
  version: "2.0"
  description: "专业的多维度文学创作分析模板"

categories:
  - id: "character"
    name: "人物塑造"
    subcategories:
      - id: "character.personality"
        name: "性格特点"
        instruction: "分析主要人物的性格特征、心理活动和性格发展..."
      - id: "character.relationship"
        name: "人物关系"
        instruction: "分析人物之间的关系网络、互动模式..."
  
  - id: "plot"
    name: "情节构建"
    subcategories:
      - id: "plot.structure"
        name: "叙事结构"
        instruction: "分析作品的叙事结构、情节安排..."
```

### 4. 应用配置（config/app_config.yaml）

```yaml
# 日志级别
logging_level: DEBUG

# 其他应用配置
# upload_dir: data/uploads
# cache_dir: .cache
```

### 5. 实时配置更新

系统支持实时配置更新，无需重启服务：

1. 在前端`/settings-manager`页面修改配置
2. 配置会写入`.env`文件
3. 下次API调用时自动读取最新配置

**核心机制：** `src/providers/base.py`中的`get_current_param()`方法每次调用时都从环境变量读取最新值。

---

## 使用指南

### 快速开始

#### 1. 文本分析

1. 访问`http://localhost:8080/text-analysis`
2. 上传文本文件或直接粘贴文本
3. 选择要分析的维度（情感分析、关键词提取等）
4. 选择AI服务商和模型
5. 点击"开始分析"
6. 查看分析结果和可视化图表
7. 可导出分析结果

#### 2. 文学创作分析

1. 访问`/writing-style-analysis`
2. 上传文学作品文本
3. 从V2模板中选择分析维度：
   - 人物塑造
   - 情节构建
   - 主题探讨
   - 语言风格
   - 写作技巧
4. 选择AI服务商
5. 查看专业分析报告

#### 3. 风格迁移

1. 访问`/style-transfer`
2. 输入源文本
3. 选择目标风格或自定义风格特征
4. 执行风格转换
5. 对比转换前后的文本
6. 导出转换结果

#### 4. 生成研报

1. 访问`/report-generator`
2. 输入研报主题（如"2024年AI芯片发展趋势"）
3. 选择生成方式：
   - **Ollama本地**：使用本地模型
   - **云端API**：使用云端AI服务
   - **热点话题**：基于实时热点生成
4. 等待LLM搜索和分析
5. 查看生成的Markdown格式研报
6. 编辑或导出研报

#### 5. 模型测试（聊天）

1. 访问`/model-test`
2. 选择AI服务商和模型
3. 调整模型参数（温度、最大token等）
4. 输入消息进行对话
5. 查看流式输出的回复
6. 保存对话历史

#### 6. 管理结果

1. 访问`/data-terminal`
2. 查看所有生成的结果
3. 重命名、查看或删除结果
4. 导出为Markdown、Word或文本格式

#### 7. 配置AI服务商

1. 访问`/settings-manager`
2. 查看所有支持的服务商
3. 点击服务商卡片查看详情
4. 编辑API密钥和参数
5. 测试连接状态
6. 保存配置（自动更新`.env`）

### 进阶使用

#### 自定义分析模板

1. 复制`config/promptPRO/文学创作多维分析模板 v2.yaml`
2. 修改或添加新的分析维度
3. 调整分析指令
4. 保存为新模板
5. 在代码中引用新模板

#### 添加新的AI服务商

1. 在`config/providers_meta.json`中添加服务商元数据
2. 在`.env`中添加API密钥和配置
3. 创建处理器类（继承`BaseAPIHandler`）
4. 实现`generate_text()`等方法
5. 重启服务即可使用

#### 批量处理

通过API端点进行批量处理：

```python
import requests

files = ['file1.txt', 'file2.txt', 'file3.txt']
for file in files:
    with open(file, 'r') as f:
        text = f.read()
    
    response = requests.post('http://localhost:8000/api/analyze', json={
        'text': text,
        'provider': 'deepseek_ai',
        'analysis_types': ['sentiment', 'keywords']
    })
    
    print(response.json())
```

---
## API文档

### 主要API端点

#### 1. 文本分析API

**POST /api/analyze**

```json
{
  "text": "要分析的文本内容",
  "provider": "deepseek_ai",
  "model": "deepseek-chat",
  "analysis_types": ["sentiment", "keywords", "readability"]
}
```

#### 2. 文学分析API

**GET /api/literature-analysis/template-structure**
- 获取V2文学分析模板结构

**POST /api/literature-analysis/analyze**

#### 3. 研报生成API

**POST /api/v1/reports/generate-report**

#### 4. 服务商管理API

**GET /api/providers** - 获取所有服务商列表

**PUT /api/providers/{provider_name}** - 更新服务商配置

### 完整API文档

访问：http://localhost:8000/docs（Swagger UI）

---

## 开发规范

### 代码规范

1. **Python后端**：遵循PEP 8规范
2. **Vue前端**：使用Composition API
3. **模块分离原则**：每个文件专注于一个特定功能
4. **代码复用**：创建新功能前先全局查找是否已有相关代码

### 配置管理

- .env文件是API配置的唯一真实来源
- 不在代码中硬编码API密钥
- 不提交.env文件到版本控制

---

## 故障排除

### 常见问题

**后端无法启动**：检查依赖是否安装完整

**AI服务商连接失败**：检查.env中API密钥是否正确

**Ollama本地服务连接失败**：
```bash
ollama serve
ollama pull gemma3:12b
```

---

## 项目维护

### 依赖更新

**后端**：
```bash
pip list --outdated
pip install --upgrade package_name
```

**前端**：
```bash
npm outdated
npm update package_name
```

### 备份策略

1. 定期备份数据库：data/QianLv_data.db
2. 备份配置文件：.env和config目录
3. 备份结果数据：data/output/

---

## 许可证

本项目采用 MIT License

---

## 联系与致谢

感谢所有开源项目的支持：Vue.js、FastAPI、Element Plus、ECharts、Ollama等

**最后更新：** 2025-12-26

**版本：** 1.0.0

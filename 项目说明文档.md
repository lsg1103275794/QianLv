# 千虑 (QianLv) - AI驱动的智能文本处理平台

## 项目概述

千虑 (QianLv) 是一个**专业级AI文本处理平台**，利用大语言模型的强大能力，为内容创作者、研究人员、媒体从业者提供**从分析到创作的全流程智能解决方案**。

### 🎯 核心价值

**为什么选择千虑？**

1. **真正的AI赋能创作** - 不只是简单的文本分析，而是深度理解文本风格、提取创作特征，帮助你学习和模仿优秀作品的写作手法
2. **多AI服务商无缝切换** - 集成14+主流AI服务商，避免单一依赖，降低成本，提高可用性
3. **专业级文学分析** - 基于文学理论的多维度分析模板，从人物、情节、主题、语言、技巧5大维度深度剖析作品
4. **智能风格迁移** - 提取文本风格特征，实现高质量的文案改写、洗稿、风格模仿
5. **自动化研报生成** - LLM自主规划、搜索、分析、撰写，一键生成专业研究报告
6. **本地+云端双模式** - 支持Ollama本地部署（数据安全）和云端API（性能强大），灵活选择

### ✨ 核心特性

- 🔍 **多维度文本分析** - 情感分析、关键词提取、可读性评估、语言特征识别等8+分析维度
- 📚 **文学创作深度分析** - 基于专业模板的5大维度文学分析（人物、情节、主题、语言、技巧）
- 🎨 **智能风格迁移** - 提取风格特征，实现文案改写、洗稿、风格模仿（支持新闻、文学、创意等多种风格模板）
- 📊 **AI驱动研报生成** - 自动搜索、分析、撰写，生成结构化专业研报
- 🔥 **实时热点追踪** - 自动获取热点话题，快速生成热点分析报告
- 🌐 **14+AI服务商支持** - Ollama、Deepseek、Gemini、智谱AI等，灵活切换，降低依赖
- 💬 **交互式AI对话** - 内置聊天测试界面，方便调试和体验不同AI模型
- 🗄️ **统一数据管理** - 所有分析结果集中管理，支持多格式导出（Markdown/Word/Text）

### 🎯 适用场景

| 用户群体 | 应用场景 | 核心价值 |
|---------|---------|---------|
| **内容创作者** | 文案改写、风格学习、创意写作 | 学习优秀作品的写作手法，快速生成不同风格的文案 |
| **媒体从业者** | 新闻稿改写、热点分析、研报生成 | 提取新闻风格特征，快速生成热点分析和专题报告 |
| **文学研究者** | 作品分析、风格研究、比较文学 | 深度分析文学作品的多个维度，提取风格特征进行研究 |
| **学生/教师** | 论文写作、文献分析、教学辅助 | 分析学术文献风格，辅助论文写作和教学 |
| **企业用户** | 市场研报、竞品分析、内容营销 | 自动生成行业研报，分析竞品文案风格 |

### 🚀 技术栈

- **后端**：Python 3.12 + FastAPI + SQLAlchemy + Uvicorn
- **前端**：Vue 3 + Element Plus + ECharts + Vue Router
- **AI集成**：14+ LLM服务商API + Ollama本地部署
- **NLP处理**：Transformers、Sentence-Transformers、NLTK、Jieba、TextBlob
- **文件处理**：PyMuPDF、python-docx、EbookLib、pdfplumber

---

## 🌟 核心亮点

### 1️⃣ 文学分析 + 风格迁移 = 最强组合

这是千虑最独特的功能！不同于其他工具只能简单改写，千虑通过**深度文学分析**提取风格特征，实现**高质量的风格模仿**：

```
优秀文案 → 5维度深度分析 → 提取50+风格特征 → 应用到你的文本 → 高质量改写
```

**实际效果：**
- ✅ 学习名家的写作手法，应用到自己的创作
- ✅ 分析优秀文案的风格，改写出同等质量的内容
- ✅ 提取新闻稿的专业风格，快速生成符合规范的报道
- ✅ 保持原意的同时，生成完全不同的表达方式

### 2️⃣ AI自主完成研报生成全流程

不是简单的模板填充，而是让AI**自主规划、搜索、分析、撰写**：

```
输入主题 → AI规划搜索策略 → 自动搜索信息 → AI分析整合 → 生成专业研报
```

**真正的自动化：**
- ✅ AI自己决定搜索什么关键词
- ✅ AI自己分析搜索结果的价值
- ✅ AI自己组织研报的结构和内容
- ✅ 3-5分钟生成一份专业研报

### 3️⃣ 14+AI服务商无缝切换

避免单一依赖，降低成本，提高可用性：

```
同一个任务 → 可选14+服务商 → 对比效果 → 选择最优方案
```

**灵活性：**
- ✅ 本地Ollama（数据安全、无成本）
- ✅ 云端API（性能强大、效果好）
- ✅ 实时切换（无需重启服务）
- ✅ 成本优化（选择性价比最高的）

### 4️⃣ 专业的风格模板库

提供多种专业风格提取模板，适应不同场景：

| 模板 | 维度 | 适用场景 |
|------|------|---------|
| **深度创作风格** | 8维度，50+特征 | 文学作品、长文本 |
| **快速风格提取** | 5核心维度 | 短文本、快速分析 |
| **新闻风格提取** | 6新闻维度 | 新闻稿、通讯、特稿 |

**查看详细文档：**
- [风格提取模板完整指南](doc/STYLE_EXTRACTION_TEMPLATES.md)
- [新闻风格模板使用指南](doc/NEWS_STYLE_TEMPLATE_GUIDE.md)

---

## 目录

- [项目概述](#项目概述)
- [项目结构](#项目结构)
- [核心功能](#核心功能)
- [技术架构](#技术架构)
- [安装部署](#安装部署)
- [配置说明](#配置说明)
- [使用指南](#使用指南)
- [API文档](#api文档)
- [开发规范](#开发规范)

---

## 项目结构

### 完整目录树

```
千虑 (QianLv)/
├── backend_main.py              # 后端主入口文件
├── main.py                      # 简化启动入口（包装backend_main.py）
├── requirements.txt             # Python依赖清单
├── .env                         # 环境变量配置（API密钥等敏感信息）
├── .gitignore                   # Git忽略文件配置
├── 后端.bat                     # Windows快速启动脚本
│
├── frontend/                    # 前端项目目录
│   ├── package.json             # 前端依赖配置
│   ├── vue.config.js            # Vue CLI配置
│   ├── babel.config.js          # Babel编译配置
│   ├── .eslintrc.js             # ESLint代码规范配置
│   ├── public/                  # 静态资源目录
│   │   └── index.html           # HTML模板
│   ├── dist/                    # 构建输出目录（生产环境）
│   └── src/                     # 前端源代码
│       ├── App.vue              # 根组件
│       ├── main.js              # 前端入口文件
│       ├── router/              # 路由配置
│       │   └── index.js         # 路由定义
│       ├── views/               # 页面视图
│       │   ├── DataTerminal.vue           # 数据终端（结果管理）
│       │   ├── ModelTestView.vue          # 模型测试（聊天界面）
│       │   └── ReportGeneratorView.vue    # 研报生成器
│       ├── components/          # 可复用组件
│       │   ├── analysis/        # 分析相关组件
│       │   │   ├── TextAnalysis.vue       # 文本分析主界面
│       │   │   ├── WritingStyleAnalysis.vue # 写作风格分析
│       │   │   ├── AnalysisResults.vue    # 分析结果展示
│       │   │   ├── SentimentChart.vue     # 情感分析图表
│       │   │   ├── KeywordExtractionChart.vue # 关键词提取图表
│       │   │   ├── ReadabilityChart.vue   # 可读性分析图表
│       │   │   └── ...（其他分析组件）
│       │   ├── api/             # API配置相关组件
│       │   │   ├── ApiManager.vue         # API管理器主界面
│       │   │   ├── ApiProviderCard.vue    # 服务商卡片
│       │   │   ├── ApiConfigDrawer.vue    # 配置抽屉
│       │   │   ├── ApiStatusCheck.vue     # 状态检查
│       │   │   └── ...
│       │   ├── chat/            # 聊天界面组件
│       │   │   ├── ChatTest.vue           # 聊天测试主组件
│       │   │   ├── components/            # 聊天子组件
│       │   │   │   ├── ChatHeader.vue     # 聊天头部
│       │   │   │   ├── ChatMessages.vue   # 消息列表
│       │   │   │   ├── ChatInput.vue      # 输入框
│       │   │   │   └── MessageItem.vue    # 消息项
│       │   │   ├── composables/           # 可组合函数
│       │   │   ├── styles/                # 样式文件
│       │   │   └── utils/                 # 工具函数
│       │   ├── common/          # 通用组件
│       │   │   ├── ConfigForm.vue         # 配置表单
│       │   │   ├── LanguageSwitcher.vue   # 语言切换器
│       │   │   ├── ModelParamsEditor.vue  # 模型参数编辑器
│       │   │   └── ...
│       │   ├── diagnostics/     # 诊断工具组件
│       │   ├── report-generator/ # 研报生成组件
│       │   │   ├── ReportForm.vue         # 研报表单
│       │   │   ├── ReportDisplay.vue      # 研报显示
│       │   │   ├── ReportLoading.vue      # 加载状态
│       │   │   └── ReportError.vue        # 错误显示
│       │   ├── style/           # 风格迁移组件
│       │   │   └── StyleTransfer.vue      # 风格转换主界面
│       │   └── charts/          # 图表组件
│       ├── services/            # API服务层
│       │   ├── api.js           # 基础API配置
│       │   ├── apiClient.js     # API客户端
│       │   ├── analysisService.js      # 分析服务
│       │   ├── chatService.js          # 聊天服务
│       │   ├── reportService.js        # 研报服务
│       │   ├── providerService.js      # 服务商管理
│       │   ├── fileService.js          # 文件服务
│       │   ├── resultsService.js       # 结果管理服务
│       │   └── ...
│       ├── i18n/                # 国际化配置
│       │   ├── index.js         # i18n配置入口
│       │   └── locales/         # 语言文件
│       │       ├── zh-CN.js     # 简体中文
│       │       └── en-US.js     # 英文
│       ├── utils/               # 工具函数
│       └── assets/              # 静态资源
│           ├── main.css         # 主样式文件
│           ├── emojiMap.js      # Emoji映射
│           └── styles/          # 样式文件
│
├── src/                         # 后端源代码
│   ├── api/                     # API路由和模型
│   │   ├── routes/              # API路由定义
│   │   │   ├── analysis.py              # 文本分析路由
│   │   │   ├── literature_analysis.py   # 文学分析路由
│   │   │   ├── chat.py                  # 聊天路由
│   │   │   ├── chat_history.py          # 聊天历史路由
│   │   │   ├── providers.py             # 服务商管理路由
│   │   │   ├── files.py                 # 文件上传路由
│   │   │   ├── transfer.py              # 风格迁移路由
│   │   │   ├── report_generator_api.py  # 研报生成路由
│   │   │   ├── hot_topics_routes.py     # 热点话题路由
│   │   │   ├── results.py               # 结果管理路由
│   │   │   ├── tasks.py                 # 任务管理路由
│   │   │   ├── templates.py             # 模板管理路由
│   │   │   ├── settings.py              # 设置路由
│   │   │   ├── data_terminal.py         # 数据终端路由
│   │   │   ├── ui_state.py              # UI状态路由
│   │   │   └── async_tasks.py           # 异步任务路由
│   │   ├── models/              # 数据模型
│   │   │   ├── analysis.py              # 分析模型
│   │   │   ├── report_models.py         # 研报模型
│   │   │   └── hot_topic_models.py      # 热点话题模型
│   │   └── auth.py              # 认证逻辑
│   │
│   ├── core/                    # 核心业务逻辑
│   │   ├── literature_analyzer.py    # 文学分析器
│   │   ├── analyzers/           # 分析器模块
│   │   │   └── basic_analyzer.py     # 基础分析器
│   │   ├── processing/          # 文本处理模块
│   │   │   ├── chunk_splitter.py     # 文本分块
│   │   │   ├── format_enforcer.py    # 格式强制器
│   │   │   ├── post_processor.py     # 后处理器
│   │   │   ├── style_transfer.py     # 风格迁移
│   │   │   └── style_validator.py    # 风格验证
│   │   └── tasks/               # 任务管理
│   │       ├── manager.py            # 任务管理器
│   │       ├── models.py             # 任务模型
│   │       └── worker.py             # 任务执行器
│   │
│   ├── providers/               # AI服务提供商
│   │   ├── base.py              # 基础处理器类
│   │   ├── factory.py           # 处理器工厂
│   │   └── handlers/            # 各服务商处理器
│   │       ├── ollama_local.py           # Ollama本地服务
│   │       ├── ollama_report_handler.py  # Ollama研报处理器
│   │       ├── deepseek_ai.py            # Deepseek AI
│   │       ├── silicon_flow.py           # 硅基流动
│   │       ├── volc_engine.py            # 火山引擎
│   │       ├── google_gemini.py          # Google Gemini
│   │       ├── zhipu_ai.py               # 智谱AI
│   │       ├── groq_api.py               # Groq API
│   │       ├── together_ai.py            # Together AI
│   │       ├── mistral_ai.py             # Mistral AI
│   │       ├── perplexity_ai.py          # Perplexity AI
│   │       ├── open_router.py            # OpenRouter
│   │       ├── Free_Qwen3.py             # 免费Qwen3
│   │       └── ...（其他处理器）
│   │
│   ├── services/                # 业务服务层
│   │   ├── hot_topics/          # 热点话题服务
│   │   │   ├── service.py            # 服务逻辑
│   │   │   └── handler.py            # 处理器
│   │   └── report_generator/    # 研报生成服务
│   │       └── service.py            # 服务逻辑
│   │
│   ├── database/                # 数据库管理
│   │   └── manager.py           # 数据库管理器
│   │
│   ├── config/                  # 配置管理
│   │   ├── api_manager.py       # API管理器
│   │   ├── app_config.py        # 应用配置
│   │   └── analyzer_config.json # 分析器配置
│   │
│   ├── utils/                   # 工具函数
│   │   ├── logging.py           # 日志工具
│   │   ├── config.py            # 配置工具
│   │   ├── cache.py             # 缓存工具
│   │   ├── error_handler.py     # 错误处理
│   │   ├── file_utils.py        # 文件工具
│   │   ├── helpers.py           # 辅助函数
│   │   ├── retry.py             # 重试机制
│   │   ├── startup.py           # 启动处理
│   │   ├── ui_state.py          # UI状态管理
│   │   ├── config_validator.py  # 配置验证
│   │   └── provider_config_loader.py # 服务商配置加载器
│   │
│   └── validation/              # 数据验证
│       ├── schema_checker.py    # 模式检查器
│       ├── style_detector.py    # 风格检测器
│       └── error_handler.py     # 错误处理器
│
├── config/                      # 配置文件目录
│   ├── app_config.yaml          # 应用配置
│   ├── api_configs.json         # API配置
│   ├── configs.json             # 通用配置
│   ├── providers_meta.json      # 服务商元数据（14+提供商）
│   ├── provider_config_template.json # 服务商配置模板
│   ├── providers/               # 各服务商配置文件
│   │   ├── ollama_local.json    # Ollama配置
│   │   ├── open_router.json     # OpenRouter配置
│   │   └── Free_Qwen3.json      # Qwen3配置
│   ├── prompt_templates/        # 提示词模板
│   │   ├── literary_analysis.yaml            # 文学分析
│   │   ├── character_plot_analysis.yaml      # 角色情节分析
│   │   ├── theme_symbolism_analysis.yaml     # 主题象征分析
│   │   └── comprehensive_literary_review.yaml # 综合文学评论
│   ├── promptPRO/               # 专业提示词模板
│   │   └── 文学创作多维分析模板 v2.yaml    # V2多维度文学分析
│   └── validation_rules/        # 验证规则
│       ├── alpaca_schema.json   # Alpaca格式规范
│       └── style_rules.yaml     # 风格规则
│
├── data/                        # 数据目录
│   ├── QianLv_data.db        # SQLite数据库
│   ├── sensitive_words.txt      # 敏感词库
│   ├── ui_state.json            # UI状态存储
│   ├── uploads/                 # 上传文件存储
│   │   └── temp/                # 临时文件
│   └── output/                  # 输出数据
│       └── datasets/            # 数据集
│
├── .cache/                      # 缓存目录
│   ├── index/                   # 索引缓存
│   ├── style_transfer/          # 风格迁移缓存
│   ├── text_analysis/           # 文本分析缓存
│   └── text_processing/         # 文本处理缓存
│
├── conda_env/                   # Conda环境（Python 3.12）
│   ├── python.exe               # Python解释器
│   ├── Scripts/                 # 脚本工具
│   ├── Lib/                     # Python库
│   └── ...
│
├── doc/                         # 文档目录
│   ├── PROJECT_STRUCTURE.md     # 项目结构说明
│   ├── README_API_IMPROVEMENTS.md # API改进说明
│   ├── INTELLIGENT_REPORT_SYSTEM.md # 智能研报系统设计
│   ├── 数据研报功能的实现.md    # 数据研报功能实现文档
│   ├── development_log.md       # 开发日志
│   ├── api_streaming_guide.md   # API流式传输指南
│   └── MCP.md                   # MCP相关文档
│
├── Future/                      # 未来功能规划
│   └── feature_suggestions.md   # 功能建议


---

## 核心功能

### 1. 文本分析模块 📊
**路径：** `/text-analysis`  
**核心文件：** `frontend/src/components/analysis/TextAnalysis.vue` | `src/api/routes/analysis.py`

**💡 核心价值：** 快速了解文本的基本特征和质量，为深度分析和改写提供数据支撑

**功能特性：**
- **情感分析** - 识别文本情感倾向（正面/负面/中性），支持情感强度评分，帮助评估内容的情感表达效果
- **关键词提取** - 自动提取核心关键词（支持TF-IDF、TextRank算法），快速把握文本主题
- **可读性分析** - 计算Flesch可读性指数、平均句长、词汇多样性，评估内容的易读性
- **文本统计** - 字数、句子数、段落数、平均词长等基础统计，了解文本结构
- **词频分析** - 生成词云图和词频分布图表，可视化展示高频词汇
- **语言特征识别** - 分析语法结构、修辞手法、语言风格，识别文本的表达特点
- **句式模式分析** - 识别句式结构和表达模式，了解作者的写作习惯

**支持模式：**
- ⚡ **本地分析** - 使用内置算法快速分析（无需API，速度快）
- 🤖 **AI深度分析** - 调用大模型进行深度语义分析（更准确，支持14+服务商）

**支持文件格式：** TXT, PDF, DOCX, EPUB, MD（最大50MB）

### 2. 文学创作多维分析 📚
**路径：** `/writing-style-analysis`  
**核心文件：** `src/core/literature_analyzer.py` | `src/api/routes/literature_analysis.py`

**💡 核心价值：** 深度剖析文学作品的创作手法，提取可复用的风格特征，为风格迁移和创作学习提供专业支撑

**功能特性：**

#### 🎯 基于专业文学理论的V2多维度模板
使用专业的文学分析框架（`config/promptPRO/文学创作多维分析模板 v2.yaml`），从5大核心维度进行深度分析：

1. **人物塑造维度** 👤
   - 性格特点：分析人物的性格特征、心理活动、性格发展
   - 人物关系：分析人物关系网络、互动模式、冲突关系
   - 发展弧线：追踪人物的成长轨迹和转变过程

2. **情节构建维度** 📖
   - 叙事结构：分析故事的结构框架（线性/非线性/多线索）
   - 冲突设置：识别主要冲突类型和冲突发展模式
   - 节奏控制：分析情节推进的节奏和张力营造

3. **主题探讨维度** 💭
   - 核心思想：提炼作品的中心思想和价值观
   - 象征意义：分析象征手法和隐喻表达
   - 社会意义：探讨作品的社会批判和现实意义

4. **语言风格维度** ✍️
   - 修辞手法：识别比喻、拟人、排比等修辞技巧
   - 词汇选择：分析用词特点（书面/口语、雅/俗）
   - 句式特点：分析句子结构、长短句搭配、语气运用

5. **写作技巧维度** 🎨
   - 叙事视角：分析第一人称/第三人称/全知视角的运用
   - 时空处理：分析时间线索和空间场景的组织
   - 描写手法：分析细节描写、环境描写、心理描写等技巧

#### 🔗 与风格迁移深度集成

**这是千虑最强大的功能组合！** 文学创作分析不仅能帮你理解作品，更能为风格迁移提供核心数据：

- **风格特征提取** - 分析结果可直接导入风格迁移模块，作为风格样本
- **精准风格模仿** - 基于深度分析的风格特征，实现高质量的文案改写
- **创作手法学习** - 学习优秀作品的写作技巧，应用到自己的创作中

**应用场景：**
- 📝 **文案改写** - 分析优秀文案的风格，改写自己的内容
- 🔄 **洗稿润色** - 提取原文风格特征，生成不同表达的版本
- 🎓 **创作学习** - 深度学习名家作品的写作手法
- 📊 **风格研究** - 比较不同作者/作品的风格差异

#### 📋 专业分析报告

生成结构化的文学分析报告，包含：
- 各维度的详细分析结果
- 风格特征总结
- 创作手法提炼
- 可复用的风格样本数据

#### 🔧 灵活的模板系统

- **可选维度分析** - 用户可自由选择需要分析的维度，节省时间和成本
- **模板可扩展** - 支持自定义分析模板和维度，适应不同分析需求
- **多种风格模板** - 提供文学、新闻、创意等多种专业模板

### 3. 智能风格迁移模块 🎨
**路径：** `/style-transfer`  
**核心文件：** `frontend/src/components/style/StyleTransfer.vue` | `src/core/processing/style_transfer.py`

**💡 核心价值：** 这是千虑的杀手级功能！基于深度风格分析，实现高质量的文本改写和风格转换

**功能特性：**

#### 🎯 三种风格迁移模式

1. **基于文学分析的风格迁移** ⭐ **最强大**
   - 导入「文学创作分析」模块生成的风格样本
   - 基于5大维度的深度风格特征进行改写
   - 实现最高质量的风格模仿和文案改写
   - **适用场景**：高质量文案改写、深度洗稿、风格学习

2. **基于专业模板的风格迁移** 🎓 **最专业**
   - 使用预设的专业风格模板（新闻、文学、创意等）
   - 提供多种风格提取模板：
     - **深度创作风格提取模板** - 8大维度，50+细分特征，适合长文本和专业作品
     - **快速风格提取模板** - 5大核心维度，轻量级快速分析，适合短文本
     - **新闻风格提取模板** - 6大新闻专业维度，符合新闻行业标准
   - **适用场景**：新闻稿改写、专业文档转换、特定风格模仿

3. **自定义风格转换** 🔧 **最灵活**
   - 用户自定义目标风格特征
   - 支持正式/非正式、学术/通俗、文言/白话等预设风格
   - **适用场景**：快速风格调整、简单改写

#### 📋 专业风格模板库

| 模板名称 | 分析维度 | 适用场景 | 文档链接 |
|---------|---------|---------|---------|
| **深度创作风格提取** | 8大维度，50+特征 | 长文本、文学作品、深度分析 | [查看文档](doc/STYLE_EXTRACTION_TEMPLATES.md) |
| **快速风格提取** | 5大核心维度 | 短文本、快速分析、风格迁移 | [查看文档](doc/STYLE_EXTRACTION_TEMPLATES.md) |
| **新闻风格提取** | 6大新闻维度 | 新闻稿、通讯、特稿、评论 | [查看文档](doc/NEWS_STYLE_TEMPLATE_GUIDE.md) |

#### 🔄 完整的风格迁移工作流

```
原文 → 文学分析（提取风格） → 风格样本 → 风格迁移 → 改写文本 → 风格验证
```

1. **风格提取** - 使用文学分析或模板提取源文本的风格特征
2. **风格应用** - 将提取的风格特征应用到目标文本
3. **风格验证** - 自动验证转换后的文本是否符合目标风格
4. **结果优化** - 根据验证结果进行迭代优化

#### 💼 实际应用场景

| 场景 | 工作流程 | 价值 |
|------|---------|------|
| **文案改写** | 分析优秀文案 → 提取风格 → 改写自己的文案 | 学习优秀文案的表达方式，提升文案质量 |
| **洗稿润色** | 分析原文风格 → 保持风格 → 重新表达 | 保持原意和风格，避免抄袭，提升原创性 |
| **新闻改写** | 使用新闻模板 → 提取新闻风格 → 改写报道 | 符合新闻规范，快速生成不同角度的报道 |
| **风格学习** | 分析名家作品 → 提取写作手法 → 应用到创作 | 学习大师的写作技巧，提升创作水平 |
| **多版本生成** | 一次分析 → 多次迁移 → 生成多个版本 | 快速生成不同风格的内容版本 |

#### 🚀 技术特性

- **风格分析缓存** - 缓存风格分析结果，提高效率，降低成本
- **智能风格验证** - 自动验证转换效果，确保质量
- **批量处理支持** - 支持批量文本的风格迁移
- **多模型支持** - 支持14+AI服务商，选择最适合的模型

### 4. AI驱动的智能研报生成系统 📈
**路径：** `/report-generator`  
**核心文件：** `src/services/report_generator/service.py` | `src/api/routes/report_generator_api.py`

**💡 核心价值：** 让AI自主完成研报生成的全流程：规划→搜索→分析→撰写，真正实现自动化研报生成

**功能特性：**

#### 🤖 LLM驱动的自动化工作流

传统研报生成需要人工完成多个步骤，千虑让AI自主完成整个流程：

```
用户输入主题 → LLM规划搜索策略 → 调用搜索工具 → 获取实时信息 
→ LLM分析整合 → 生成结构化研报 → 输出Markdown文档
```

**关键特点：**
- ✅ **自主规划** - LLM根据主题自动规划需要搜索的关键词和维度
- ✅ **实时搜索** - 调用Web搜索API获取最新信息（支持Serper API）
- ✅ **智能分析** - LLM分析搜索结果，提取关键信息，形成观点
- ✅ **结构化输出** - 按照专业研报格式生成内容

#### 📊 三种生成模式

1. **Ollama本地生成** 🏠
   - 使用本地部署的Ollama模型
   - **优势**：数据安全、无API成本、无网络依赖
   - **适用**：敏感主题、内部研报、成本控制

2. **云端API生成** ☁️
   - 使用云端AI服务（支持14+服务商）
   - **优势**：性能强大、效果更好、无需本地资源
   - **适用**：高质量研报、复杂分析、快速生成

3. **基于热点话题生成** 🔥
   - 从实时热点中筛选相关内容
   - **优势**：紧跟热点、快速响应、内容时效性强
   - **适用**：热点分析、舆情研报、快速响应

#### 📋 专业研报结构

生成的研报包含以下标准章节：

1. **执行摘要** - 核心观点和主要发现的简明总结
2. **背景介绍** - 主题背景、研究意义、相关概念
3. **详细分析** - 按维度展开的深度分析
   - 市场现状分析
   - 技术发展趋势
   - 竞争格局分析
   - 政策环境分析
4. **关键数据点** - 重要数据和统计信息
5. **趋势预测** - 未来发展趋势和可能的变化
6. **结论与建议** - 总结性观点和行动建议

#### 💼 实际应用场景

| 场景 | 示例主题 | 生成时间 |
|------|---------|---------|
| **行业研报** | "2024年AI芯片发展趋势" | 3-5分钟 |
| **市场分析** | "新能源汽车市场竞争格局" | 3-5分钟 |
| **技术研究** | "大语言模型的最新进展" | 3-5分钟 |
| **热点分析** | "某热点事件的影响分析" | 2-3分钟 |
| **竞品分析** | "主流AI产品对比分析" | 3-5分钟 |

#### 🚀 技术特性

- **流式输出** - 实时显示生成进度，提升用户体验
- **Markdown格式** - 支持富文本格式，可直接导出使用
- **多格式导出** - 支持导出为Markdown、Word、PDF等格式
- **结果管理** - 所有生成的研报统一管理，方便查阅和复用

### 5. 热点话题追踪 🔥
**路径：** `/api/v1/hot-topics`  
**核心文件：** `src/services/hot_topics/service.py` | `src/services/hot_topics/handler.py`

**功能特性：**
- **实时热点获取**：通过Serper API或模拟搜索获取热点信息
- **热点分类**：自动分类热点话题（科技、财经、社会等）
- **热度评分**：计算话题的相关性和热度评分
- **来源追踪**：记录热点信息的来源媒体和URL
- **智能摘要**：对热点内容进行自动摘要
- **关键词提取**：提取热点话题的核心关键词

### 6. 多AI服务商统一管理 🤖
**路径：** `/settings-manager`  
**核心文件：** `frontend/src/components/api/ApiManager.vue` | `src/providers/factory.py`

**💡 核心价值：** 避免单一AI服务商依赖，降低成本，提高可用性，灵活选择最适合的模型

**支持的AI服务商（14+）：**

| 服务商 | 类型 | 特点 | 推荐场景 |
|--------|------|------|---------|
| **Ollama Local** | 本地 | 私有部署，数据安全，无API成本 | 敏感数据、成本控制 |
| **Deepseek AI** | 云端 | 性价比高，中文优秀，推理能力强 | 日常使用、中文任务 |
| **Google Gemini** | 云端 | 多模态能力强，上下文长 | 长文本、多模态 |
| **Silicon Flow** | 云端 | 国内访问快，模型丰富 | 国内用户、快速响应 |
| **Zhipu AI** | 云端 | 智谱清言，中文理解好 | 中文任务、专业分析 |
| **Groq** | 云端 | 推理速度极快，实时响应 | 实时对话、快速生成 |
| **OpenRouter** | 云端 | 多模型聚合，一个API访问多个模型 | 模型对比、灵活切换 |
| **Volc Engine** | 云端 | 火山引擎，长文本支持好 | 长文本分析、研报生成 |
| **Together AI** | 云端 | 开源模型托管，价格实惠 | 成本控制、开源模型 |
| **Mistral AI** | 云端 | 欧洲AI，多语言支持 | 多语言任务 |
| **Perplexity AI** | 云端 | 搜索增强，实时信息 | 研报生成、信息检索 |
| **Free Qwen3** | 云端 | 免费Qwen3服务 | 测试、学习 |
| **Anyscale** | 云端 | 企业级部署 | 企业用户 |
| **Cohere** | 云端 | 企业AI解决方案 | 企业应用 |

**管理功能：**

#### 🎛️ 统一配置界面
- **可视化配置** - 无需手动编辑配置文件，通过UI界面配置所有服务商
- **实时参数更新** - 修改配置后无需重启服务，下次调用自动生效
- **参数可视化编辑** - 温度、最大token数、Top-P等参数直观调整

#### 🔍 连接状态检测
- **一键测试** - 测试API连接和模型可用性
- **状态监控** - 实时显示各服务商的连接状态
- **错误诊断** - 详细的错误信息和解决建议

#### 🔐 API密钥管理
- **安全存储** - API密钥加密存储在`.env`文件
- **批量配置** - 一次性配置多个服务商
- **快速切换** - 在不同功能模块中快速切换服务商

#### 💰 成本优化建议

| 任务类型 | 推荐服务商 | 原因 |
|---------|-----------|------|
| **日常文本分析** | Ollama Local / Deepseek | 成本低，效果好 |
| **高质量研报** | Google Gemini / GPT-4 | 质量高，推理能力强 |
| **实时对话** | Groq / Deepseek | 响应快，体验好 |
| **长文本处理** | Volc Engine / Gemini | 上下文长，支持好 |
| **测试开发** | Free Qwen3 / Ollama | 免费，无限制 |

### 7. 交互式AI对话测试 💬
**路径：** `/model-test`  
**核心文件：** `frontend/src/views/ModelTestView.vue` | `src/api/routes/chat.py`

**💡 核心价值：** 快速测试和对比不同AI模型的效果，找到最适合你任务的模型

**功能特性：**

#### 🎯 多模型对话测试
- **14+服务商支持** - 在同一界面测试所有支持的AI模型
- **实时切换** - 随时切换模型，对比不同模型的回复效果
- **参数调整** - 实时调整温度、最大token等参数，观察效果变化

#### ⚡ 流式输出体验
- **SSE流式响应** - 实时显示AI生成的回复，无需等待
- **打字机效果** - 模拟真实对话体验
- **中断支持** - 可随时中断生成过程

#### 📝 对话管理
- **历史记录** - 自动保存对话历史，方便回顾
- **上下文维护** - 保持多轮对话的连贯性
- **对话导出** - 导出对话记录为Markdown格式

#### 🎨 富文本支持
- **Markdown渲染** - 支持标题、列表、表格等富文本格式
- **代码高亮** - 自动识别和高亮代码块（支持多种语言）
- **LaTeX公式** - 支持数学公式渲染（如果需要）
- **思考过程** - 显示AI的思考过程（部分模型支持）

#### 💼 实际应用场景
- **模型选型** - 对比不同模型的效果，选择最适合的
- **参数调优** - 测试不同参数对生成效果的影响
- **功能验证** - 验证AI服务商的连接和功能
- **创意探索** - 快速测试创意想法和提示词

### 8. 数据终端（统一结果管理）🗄️
**路径：** `/data-terminal`  
**核心文件：** `frontend/src/views/DataTerminal.vue` | `src/api/routes/results.py`

**💡 核心价值：** 统一管理所有分析和生成的结果，方便查阅、编辑、导出和复用

**功能特性：**

#### 📊 统一结果管理
- **集中展示** - 所有模块的结果统一展示（文本分析、文学分析、风格迁移、研报等）
- **分类筛选** - 按类型、时间、服务商等维度筛选结果
- **快速搜索** - 支持关键词搜索，快速定位需要的结果

#### 📝 结果编辑
- **在线编辑** - 直接在数据终端编辑结果内容
- **Markdown支持** - 支持Markdown格式编辑和预览
- **版本保存** - 编辑后自动保存，支持撤销

#### 📤 多格式导出
- **Markdown (.md)** - 保留格式，适合文档编辑
- **Word文档 (.docx)** - 适合正式文档和报告
- **纯文本 (.txt)** - 简单文本，通用性强
- **批量导出** - 支持批量选择和导出

#### 🏷️ 元数据管理
- **详细信息** - 显示生成时间、使用模型、来源模块等元数据
- **自定义标签** - 为结果添加标签，方便分类
- **结果重命名** - 自定义结果名称，便于识别

#### 🔄 结果复用
- **快速复制** - 一键复制结果内容
- **导入风格迁移** - 文学分析结果可直接导入风格迁移模块
- **结果对比** - 对比不同模型或参数的生成结果

#### 💼 实际应用场景
- **结果归档** - 长期保存重要的分析结果
- **团队协作** - 导出结果分享给团队成员
- **内容复用** - 将分析结果应用到新的创作中
- **效果对比** - 对比不同方法的分析效果

---
## 安装部署

### 环境要求

**后端环境：**
- Python 3.12+
- Conda（推荐）或虚拟环境
- 至少4GB可用内存
- 磁盘空间：至少10GB（包含模型缓存）

**前端环境：**
- Node.js 16+ 
- npm 8+ 或 yarn

**可选（本地模型）：**
- Ollama（用于本地模型部署）
- CUDA支持的GPU（加速推理，可选）

### 安装步骤

#### 1. 克隆项目
```bash
git clone <repository-url>
cd QianLv
```

#### 2. 后端安装

**方法一：使用项目自带的Conda环境（推荐）**
```bash
# 项目已包含conda_env目录，直接使用
# Windows:
.\conda_env\python.exe -m pip install -r requirements.txt

# Linux/Mac:
./conda_env/bin/python -m pip install -r requirements.txt
```

**方法二：创建新的Conda环境**
```bash
# 创建Python 3.12环境
conda create -n QianLv python=3.12
conda activate QianLv

# 安装依赖
pip install -r requirements.txt
```

**方法三：使用虚拟环境**
```bash
# 创建虚拟环境
python -m venv venv

# 激活虚拟环境
# Windows:
venv\Scripts\activate
# Linux/Mac:
source venv/bin/activate

# 安装依赖
pip install -r requirements.txt
```

#### 3. 前端安装

```bash
cd frontend
npm install
# 或使用 yarn
yarn install
```

#### 4. 配置环境变量

复制并编辑`.env`文件，配置API密钥和服务端点：

```bash
# 编辑 .env 文件
# 至少配置一个AI服务商的API密钥

# 示例：配置Ollama本地服务
OLLAMA_ENDPOINT=http://localhost:11434
OLLAMA_DEFAULT_MODEL=gemma3:12b

# 或配置云端服务
DEEPSEEK_API_KEY=your_api_key_here
DEEPSEEK_DEFAULT_MODEL=deepseek-chat

# 配置搜索API（用于研报生成）
SERPER_API_KEY=your_serper_api_key
```

#### 5. 初始化数据库

```bash
# 数据库会在首次启动时自动创建
# 位置：data/QianLv_data.db
```

### 启动应用

#### 开发模式

**启动后端：**
```bash
# 方法一：使用Python直接运行
python backend_main.py

# 方法二：使用uvicorn
uvicorn backend_main:app --reload --host 0.0.0.0 --port 8000

# 方法三：Windows快捷启动
.\后端.bat
```

**启动前端：**
```bash
cd frontend
npm run serve
# 或
yarn serve
```

前端默认访问地址：`http://localhost:8080`  
后端API地址：`http://localhost:8000`  
API文档地址：`http://localhost:8000/docs`

#### 生产模式

**1. 构建前端：**
```bash
cd frontend
npm run build
# 构建产物在 frontend/dist/
```

**2. 启动后端（会自动服务前端静态文件）：**
```bash
# 使用生产配置
python backend_main.py

# 或使用gunicorn（Linux/Mac）
gunicorn -w 4 -k uvicorn.workers.UvicornWorker backend_main:app --bind 0.0.0.0:8000
```

访问地址：`http://localhost:8000`

### Docker部署（可选）

**创建Dockerfile：**
```dockerfile
FROM python:3.12-slim

WORKDIR /app

# 安装系统依赖
RUN apt-get update && apt-get install -y \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# 复制依赖文件
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# 复制项目文件
COPY . .

# 构建前端
WORKDIR /app/frontend
RUN npm install && npm run build

# 返回项目根目录
WORKDIR /app

# 暴露端口
EXPOSE 8000

# 启动命令
CMD ["python", "backend_main.py"]
```

**构建和运行：**
```bash
docker build -t QianLv .
docker run -p 8000:8000 -v G:\work\QianLv/.env:/app/.env QianLv
```

---

## 配置说明

### 1. 环境变量配置（.env）

`.env`文件是配置的核心，包含所有API密钥和服务配置：

```bash
# === 默认服务商 ===
DEFAULT_PROVIDER='ollama_local'

# === Ollama本地服务 ===
OLLAMA_ENDPOINT='http://localhost:11434'
OLLAMA_DEFAULT_MODEL='gemma3:12b'
OLLAMA_TEMPERATURE='0.85'
OLLAMA_MAX_TOKENS='100000'

# === Deepseek AI ===
DEEPSEEK_API_KEY='your_api_key'
DEEPSEEK_ENDPOINT='https://api.deepseek.com'
DEEPSEEK_DEFAULT_MODEL='deepseek-chat'
DEEPSEEK_TEMPERATURE='0.95'
DEEPSEEK_MAX_TOKENS='8096'

# === Google Gemini ===
GOOGLE_API_KEY='your_google_api_key'
GOOGLE_DEFAULT_MODEL='gemini-1.5-flash-latest'

# === 搜索服务（研报生成） ===
SERPER_API_KEY='your_serper_api_key'

# === 系统配置 ===
LOG_LEVEL='DEBUG'
CACHE_SIZE='512'
```

### 2. 服务商元数据（config/providers_meta.json）

定义所有支持的AI服务商及其配置映射关系：

```json
[
  {
    "standard_name": "ollama_local",
    "display_name": "Ollama Local",
    "handler_module_path": "src.providers.handlers.ollama_local",
    "handler_class_name": "OllamaLocalHandler",
    "aliases": ["ollama", "ollamalocal"],
    "env_prefix": "OLLAMA_",
    "config_path": "config/providers/ollama_local.json"
  }
]
```

### 3. 提示词模板配置

**文学分析模板（config/promptPRO/文学创作多维分析模板 v2.yaml）：**

```yaml
metadata:
  name: "文学创作多维分析模板 v2"
  version: "2.0"
  description: "专业的多维度文学创作分析模板"

categories:
  - id: "character"
    name: "人物塑造"
    subcategories:
      - id: "character.personality"
        name: "性格特点"
        instruction: "分析主要人物的性格特征、心理活动和性格发展..."
      - id: "character.relationship"
        name: "人物关系"
        instruction: "分析人物之间的关系网络、互动模式..."
  
  - id: "plot"
    name: "情节构建"
    subcategories:
      - id: "plot.structure"
        name: "叙事结构"
        instruction: "分析作品的叙事结构、情节安排..."
```

### 4. 应用配置（config/app_config.yaml）

```yaml
# 日志级别
logging_level: DEBUG

# 其他应用配置
# upload_dir: data/uploads
# cache_dir: .cache
```

### 5. 实时配置更新

系统支持实时配置更新，无需重启服务：

1. 在前端`/settings-manager`页面修改配置
2. 配置会写入`.env`文件
3. 下次API调用时自动读取最新配置

**核心机制：** `src/providers/base.py`中的`get_current_param()`方法每次调用时都从环境变量读取最新值。

---

## 使用指南

### 快速开始

#### 1. 文本分析

1. 访问`http://localhost:8080/text-analysis`
2. 上传文本文件或直接粘贴文本
3. 选择要分析的维度（情感分析、关键词提取等）
4. 选择AI服务商和模型
5. 点击"开始分析"
6. 查看分析结果和可视化图表
7. 可导出分析结果

#### 2. 文学创作分析

1. 访问`/writing-style-analysis`
2. 上传文学作品文本
3. 从V2模板中选择分析维度：
   - 人物塑造
   - 情节构建
   - 主题探讨
   - 语言风格
   - 写作技巧
4. 选择AI服务商
5. 查看专业分析报告

#### 3. 风格迁移

1. 访问`/style-transfer`
2. 输入源文本
3. 选择目标风格或自定义风格特征
4. 执行风格转换
5. 对比转换前后的文本
6. 导出转换结果

#### 4. 生成研报

1. 访问`/report-generator`
2. 输入研报主题（如"2024年AI芯片发展趋势"）
3. 选择生成方式：
   - **Ollama本地**：使用本地模型
   - **云端API**：使用云端AI服务
   - **热点话题**：基于实时热点生成
4. 等待LLM搜索和分析
5. 查看生成的Markdown格式研报
6. 编辑或导出研报

#### 5. 模型测试（聊天）

1. 访问`/model-test`
2. 选择AI服务商和模型
3. 调整模型参数（温度、最大token等）
4. 输入消息进行对话
5. 查看流式输出的回复
6. 保存对话历史

#### 6. 管理结果

1. 访问`/data-terminal`
2. 查看所有生成的结果
3. 重命名、查看或删除结果
4. 导出为Markdown、Word或文本格式

#### 7. 配置AI服务商

1. 访问`/settings-manager`
2. 查看所有支持的服务商
3. 点击服务商卡片查看详情
4. 编辑API密钥和参数
5. 测试连接状态
6. 保存配置（自动更新`.env`）

### 进阶使用

#### 自定义分析模板

1. 复制`config/promptPRO/文学创作多维分析模板 v2.yaml`
2. 修改或添加新的分析维度
3. 调整分析指令
4. 保存为新模板
5. 在代码中引用新模板

#### 添加新的AI服务商

1. 在`config/providers_meta.json`中添加服务商元数据
2. 在`.env`中添加API密钥和配置
3. 创建处理器类（继承`BaseAPIHandler`）
4. 实现`generate_text()`等方法
5. 重启服务即可使用

#### 批量处理

通过API端点进行批量处理：

```python
import requests

files = ['file1.txt', 'file2.txt', 'file3.txt']
for file in files:
    with open(file, 'r') as f:
        text = f.read()
    
    response = requests.post('http://localhost:8000/api/analyze', json={
        'text': text,
        'provider': 'deepseek_ai',
        'analysis_types': ['sentiment', 'keywords']
    })
    
    print(response.json())
```

---
## API文档

### 主要API端点

#### 1. 文本分析API

**POST /api/analyze**

```json
{
  "text": "要分析的文本内容",
  "provider": "deepseek_ai",
  "model": "deepseek-chat",
  "analysis_types": ["sentiment", "keywords", "readability"]
}
```

#### 2. 文学分析API

**GET /api/literature-analysis/template-structure**
- 获取V2文学分析模板结构

**POST /api/literature-analysis/analyze**

#### 3. 研报生成API

**POST /api/v1/reports/generate-report**

#### 4. 服务商管理API

**GET /api/providers** - 获取所有服务商列表

**PUT /api/providers/{provider_name}** - 更新服务商配置

### 完整API文档

访问：http://localhost:8000/docs（Swagger UI）

---

## 开发规范

### 代码规范

1. **Python后端**：遵循PEP 8规范
2. **Vue前端**：使用Composition API
3. **模块分离原则**：每个文件专注于一个特定功能
4. **代码复用**：创建新功能前先全局查找是否已有相关代码

### 配置管理

- .env文件是API配置的唯一真实来源
- 不在代码中硬编码API密钥
- 不提交.env文件到版本控制

---

## 故障排除

### 常见问题

**后端无法启动**：检查依赖是否安装完整

**AI服务商连接失败**：检查.env中API密钥是否正确

**Ollama本地服务连接失败**：
```bash
ollama serve
ollama pull gemma3:12b
```

---

## 项目维护

### 依赖更新

**后端**：
```bash
pip list --outdated
pip install --upgrade package_name
```

**前端**：
```bash
npm outdated
npm update package_name
```

### 备份策略

1. 定期备份数据库：data/QianLv_data.db
2. 备份配置文件：.env和config目录
3. 备份结果数据：data/output/

---

## 许可证

本项目采用 MIT License

---

## 联系与致谢

感谢所有开源项目的支持：Vue.js、FastAPI、Element Plus、ECharts、Ollama等

**最后更新：** 2025-12-26

**版本：** 1.0.0
